{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuningRace.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a411ecab81e9479c82de24ba1fb086b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dee886eae30941a987b686e7e83bffe4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12c81fe388ec4df79dffaffb6db6c812",
              "IPY_MODEL_504e33f9d2d44abea4a436b7cec6fe63"
            ]
          }
        },
        "dee886eae30941a987b686e7e83bffe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12c81fe388ec4df79dffaffb6db6c812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b9ffd2dacb54638aab659e8756af657",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_accb1caf4acc4c1d92187c36e2a188a9"
          }
        },
        "504e33f9d2d44abea4a436b7cec6fe63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5293ce7c70824542a80dbcaa12a9441a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 7.43kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49563b5c3b5d4d8eb42140b20b7901e7"
          }
        },
        "2b9ffd2dacb54638aab659e8756af657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "accb1caf4acc4c1d92187c36e2a188a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5293ce7c70824542a80dbcaa12a9441a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49563b5c3b5d4d8eb42140b20b7901e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa8d7dfa0ea34a5697430f2bb5b02772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dff78c1682794f55ade259e937ef4eff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ce74f01af4142f8b81c434425d5ea12",
              "IPY_MODEL_b008b2973ccc44bdbe4af17758789e62"
            ]
          }
        },
        "dff78c1682794f55ade259e937ef4eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ce74f01af4142f8b81c434425d5ea12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7a1ec75073f4aeebdf8b7db960de296",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16d6c05772704f1f8433867ae00cc703"
          }
        },
        "b008b2973ccc44bdbe4af17758789e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_855188470d9342448f67d4dd5c9c4596",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 51.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2e3b9b730b8468da72dbd7b1b0c99c7"
          }
        },
        "e7a1ec75073f4aeebdf8b7db960de296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16d6c05772704f1f8433867ae00cc703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "855188470d9342448f67d4dd5c9c4596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2e3b9b730b8468da72dbd7b1b0c99c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kh6kyDsZfSa"
      },
      "source": [
        "# Fachpraktikum AI University Stuttgart\n",
        "Author: Siyu Chen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s2KppPnaTOi"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UBzhGwElKT4",
        "outputId": "f215cee3-79f3-4e70-8649-99c011094d86"
      },
      "source": [
        "!pip install --quiet lineflow\n",
        "!pip install --quiet transformers\n",
        "!pip install --quiet pytorch-lightning"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for lineflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for arrayfiles (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 20.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 54.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 849kB 20.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 50.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 47.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 58.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 50.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 56.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 43.9MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnt_dJL-aGDH"
      },
      "source": [
        "## Import libraries which are needed for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmVZtxllk8w9"
      },
      "source": [
        "from typing import Dict\n",
        "from pathlib import Path\n",
        "import json\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import lineflow as lf\n",
        "from transformers import BertForMultipleChoice, BertTokenizer, AdamW\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykmf-YTlc7u6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idQnyRDId1lj"
      },
      "source": [
        "### Useful function to process dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFOG_GiplB9h"
      },
      "source": [
        "MAX_LEN = 128\n",
        "NUM_LABELS = 4\n",
        "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
        "\n",
        "\n",
        "def raw_samples_to_dataset(samples):\n",
        "    datas = []\n",
        "    for sample in samples:\n",
        "        for idx in range(len(sample[\"answers\"])):\n",
        "            _id = sample[\"id\"]\n",
        "            _article = sample[\"article\"]\n",
        "            _answer = sample[\"answers\"][idx]\n",
        "            _options = sample[\"options\"][idx]\n",
        "            _question = sample[\"questions\"][idx]\n",
        "\n",
        "            data = {\n",
        "                    \"id\": _id,\n",
        "                    \"article\": _article,\n",
        "                    \"answer\": _answer,\n",
        "                    \"options\": _options,\n",
        "                    \"question\": _question,\n",
        "                    }\n",
        "            datas.append(data)\n",
        "    return lf.Dataset(datas)\n",
        "\n",
        "\n",
        "def preprocess(tokenizer: BertTokenizer, x: Dict) -> Dict:\n",
        "\n",
        "    choices_features = []\n",
        "\n",
        "    option: str\n",
        "    for option in x[\"options\"]:\n",
        "        text_a = x[\"article\"]\n",
        "        if x[\"question\"].find(\"_\") != -1:\n",
        "            text_b = x[\"question\"].replace(\"_\", option)\n",
        "        else:\n",
        "            text_b = x[\"question\"] + \" \" + option\n",
        "\n",
        "        inputs = tokenizer.encode_plus(\n",
        "                text_a,\n",
        "                text_b,\n",
        "                add_special_tokens=True,\n",
        "                max_length=MAX_LEN\n",
        "                )\n",
        "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        pad_token_id = tokenizer.pad_token_id\n",
        "        padding_length = MAX_LEN - len(input_ids)\n",
        "        input_ids = input_ids + ([pad_token_id] * padding_length)\n",
        "        attention_mask = attention_mask + ([0] * padding_length)\n",
        "        token_type_ids = token_type_ids + ([pad_token_id] * padding_length)\n",
        "\n",
        "        assert len(input_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(input_ids), MAX_LEN)\n",
        "        assert len(attention_mask) == MAX_LEN, \"Error with input length {} vs {}\".format(len(attention_mask), MAX_LEN)\n",
        "        assert len(token_type_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(token_type_ids), MAX_LEN)\n",
        "\n",
        "        choices_features.append({\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"token_type_ids\": token_type_ids,\n",
        "            })\n",
        "\n",
        "    labels = label_map.get(x[\"answer\"], -1)\n",
        "    label = torch.tensor(labels).long()\n",
        "\n",
        "    return {\n",
        "            \"id\": x[\"id\"],\n",
        "            \"label\": label,\n",
        "            \"input_ids\": torch.tensor([cf[\"input_ids\"] for cf in choices_features]),\n",
        "            \"attention_mask\": torch.tensor([cf[\"attention_mask\"] for cf in choices_features]),\n",
        "            \"token_type_ids\": torch.tensor([cf[\"token_type_ids\"] for cf in choices_features]),\n",
        "            }\n",
        "\n",
        "\n",
        "def get_dataloader(datadir: str, cachedir: str = \"./\"):\n",
        "    datadir = Path(datadir)\n",
        "    cachedir = Path(cachedir)\n",
        "    batch_size = 8\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "    preprocessor = partial(preprocess, tokenizer)\n",
        "\n",
        "    train_samples = []\n",
        "    for grade in (\"middle\", \"high\"):\n",
        "        for _path in (datadir / \"train\" / grade).iterdir():\n",
        "            train_samples.append(json.loads(_path.read_text()))\n",
        "    train = raw_samples_to_dataset(train_samples)\n",
        "    train_dataloader = DataLoader(\n",
        "            train.map(preprocessor).save(cachedir / \"train.cache\"),\n",
        "            sampler=RandomSampler(train),\n",
        "            batch_size=batch_size\n",
        "            )\n",
        "\n",
        "    val_samples = []\n",
        "    for grade in (\"middle\", \"high\"):\n",
        "        for _path in (datadir / \"dev\" / grade).iterdir():\n",
        "            val_samples.append(json.loads(_path.read_text()))\n",
        "    val = raw_samples_to_dataset(val_samples)\n",
        "    val_dataloader = DataLoader(\n",
        "            val.map(preprocessor).save(cachedir / \"val.cache\"),\n",
        "            sampler=SequentialSampler(val),\n",
        "            batch_size=batch_size\n",
        "            )\n",
        "\n",
        "    test_samples = []\n",
        "    for grade in (\"middle\", \"high\"):\n",
        "        for _path in (datadir / \"test\" / grade).iterdir():\n",
        "            test_samples.append(json.loads(_path.read_text()))\n",
        "    test = raw_samples_to_dataset(test_samples)\n",
        "    test_dataloader = DataLoader(\n",
        "            test.map(preprocessor).save(cachedir / \"test.cache\"),\n",
        "            sampler=SequentialSampler(test),\n",
        "            batch_size=batch_size\n",
        "            )\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsf2Mk0mdFZK"
      },
      "source": [
        "### Method 1: Download dataset and unzip dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fk9XAzZdUey"
      },
      "source": [
        "#### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ckit1Ol3qh",
        "outputId": "6ce64c38-38bf-4c49-b3a8-224b8520ca6d"
      },
      "source": [
        "!ls \n",
        "!wget http://www.cs.cmu.edu/~glai1/data/race/RACE.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "--2021-05-01 22:18:11--  http://www.cs.cmu.edu/~glai1/data/race/RACE.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25443609 (24M) [application/x-gzip]\n",
            "Saving to: ‘RACE.tar.gz’\n",
            "\n",
            "RACE.tar.gz         100%[===================>]  24.26M  1.28MB/s    in 12s     \n",
            "\n",
            "2021-05-01 22:18:23 (2.04 MB/s) - ‘RACE.tar.gz’ saved [25443609/25443609]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnE6ivhqdfWX"
      },
      "source": [
        "#### Unzip dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVA_Bvk5namn",
        "outputId": "2a9c681c-562c-407a-dbb2-aeea6faa24a6"
      },
      "source": [
        "!ls \n",
        "!tar -xf RACE.tar.gz && ls "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RACE.tar.gz  sample_data\n",
            "RACE  RACE.tar.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D96OKgqUn9nT",
        "outputId": "f22c1a43-ef51-4d79-e1b4-9ef92cbc502a"
      },
      "source": [
        "!cd RACE && ls && pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev  test  train\n",
            "/content/RACE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZNZZJchd-vt"
      },
      "source": [
        "#### Call functions to handle raw dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8o9Dkay1AvG"
      },
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = get_dataloader('/content/RACE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR7F_VCq0x_V",
        "outputId": "85fb2cc8-d264-494a-b233-dcda992321bd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RACE  RACE.tar.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fn6m5gRfR1j"
      },
      "source": [
        "#### Copy `train.cache`, `val.cache` and `test.cache` into Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHEov6FXPu5V"
      },
      "source": [
        "!ls\n",
        "!cp train.cache /content/drive/My\\ Drive/Fachpraktikum/\n",
        "!cp val.cache /content/drive/My\\ Drive/Fachpraktikum/\n",
        "!cp test.cache /content/drive/My\\ Drive/Fachpraktikum/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-bTsWFbe_6E"
      },
      "source": [
        "#### Check whether `train.cache`, `val.cache` and `test.cache` are saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sL9BtUePOMB"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHl9f2XxeIRS"
      },
      "source": [
        "### Method 2: Load `DataLoader` from the path which e.g. `train.cache`, `val.cache` and `test.cache`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNjkAw8aewFM"
      },
      "source": [
        "#### Mounting Google Drive locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt4gKpGVPh32",
        "outputId": "8be808f3-4dec-48ff-c3d1-b1fbae18aac5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch7aimPMfrPI"
      },
      "source": [
        "#### Check whether `train.cache`, `val.cache` and `test.cache` are in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlhYgla_Ql5o",
        "outputId": "f43786fc-99ee-4243-df06-748da39ea271"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Fachpraktikum/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.cache  train.cache  val.cache\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdlBZ2s1f4b0"
      },
      "source": [
        "#### Load from Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqZXsA99X1GR",
        "outputId": "3a97fe0f-cd10-4fb1-8ad3-e17bd6677f79"
      },
      "source": [
        "train_dataloader_drive, val_dataloader_drive, test_dataloader_drive = get_dataloader('/content/RACE', '/content/drive/My Drive/Fachpraktikum/')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from /content/drive/My Drive/Fachpraktikum/train.cache...\n",
            "Loading data from /content/drive/My Drive/Fachpraktikum/val.cache...\n",
            "Loading data from /content/drive/My Drive/Fachpraktikum/test.cache...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyWCjsYEidWm"
      },
      "source": [
        "## Play around with `DataLoader`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX29d_V2iwwG"
      },
      "source": [
        "### Get a batch of dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRTt91ytx0Wg"
      },
      "source": [
        "sample = next(iter(test_dataloader_drive))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViMgojHxi2DG"
      },
      "source": [
        "### Print some information of dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GnTDxdaymAl",
        "outputId": "e4600a1d-1801-423c-8fb9-3ebcf392fde0"
      },
      "source": [
        "# type of sample\n",
        "print(type(sample))\n",
        "# keys of sample\n",
        "print(sample.keys())\n",
        "# ids of sample\n",
        "print(sample['id'])\n",
        "# label of sample\n",
        "print(sample['label'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['id', 'label', 'input_ids', 'attention_mask', 'token_type_ids'])\n",
            "['middle6853.txt', 'middle6853.txt', 'middle6853.txt', 'middle5870.txt', 'middle5870.txt', 'middle5870.txt', 'middle7476.txt', 'middle7476.txt']\n",
            "tensor([1, 3, 1, 0, 1, 2, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSpZpJYY0iZG",
        "outputId": "eaf2db30-606a-48d1-d18d-26aaa204c8eb"
      },
      "source": [
        "# tokenised context and question\n",
        "print(sample['input_ids'][0].size())\n",
        "print(sample['input_ids'][0][0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 128])\n",
            "tensor([ 101, 2023, 2095, 1010, 1000, 3748, 2859, 1000, 2003, 3297, 1010, 2009,\n",
            "        3065, 2149, 1996, 3376, 5019, 1012, 2021, 1999, 2755, 1010, 1996, 4044,\n",
            "        2105, 2149, 2003, 2893, 4788, 1998, 4788, 1012, 1999, 2070, 3182, 1010,\n",
            "        2057, 2064, 1005, 1056, 2156, 3869, 5742, 1999, 1996, 2314, 2030, 3628,\n",
            "        2006, 1996, 4020, 1012, 2116, 4176, 2024, 5307, 1996, 5473, 1997, 2542,\n",
            "        1012, 2012, 1996, 2168, 2051, 1010, 2158, 2003, 4288, 4176, 2074, 2005,\n",
            "        2893, 2037, 3096, 1998, 6240, 1012, 1999, 2256, 2406, 1010, 1996, 2193,\n",
            "        1997, 3748, 4176, 2003, 3352, 3760, 1998, 3760, 1012, 2070, 1997, 2068,\n",
            "        2024, 2130, 5996, 2041, 1012, 2009, 1005, 1055, 2051, 2000, 4047, 2256,\n",
            "        4044, 1012, 2021, 2054, 2064, 2057, 2079, 1029,  102, 2054, 2055, 2256,\n",
            "        4044, 2105, 2149, 1999, 2755, 1029, 2488,  102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DtiQ-Q4jXho"
      },
      "source": [
        "### Decode tokenised context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRH6g1D706WW"
      },
      "source": [
        "de_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "khPEjv_Z1AEk",
        "outputId": "f31e43d4-5bb7-41c3-97ea-244f162d5fa0"
      },
      "source": [
        "de_tokenizer.decode(sample['input_ids'][0][1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] this year, \" wild china \" is famous, it shows us the beautiful scenes. but in fact, the environment around us is getting worse and worse. in some places, we can\\'t see fish swimming in the river or trees on the mountains. many animals are facing the danger of living. at the same time, man is killing animals just for getting their skin and meat. in our country, the number of wild animals is becoming smaller and smaller. some of them are even dying out. it\\'s time to protect our environment. but what can we do? [SEP] what about our environment around us in fact? worse [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd956g7TjvGu"
      },
      "source": [
        "## Model for training and evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3ZVu_Uj39l"
      },
      "source": [
        "### Load a pre-trained bert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "a411ecab81e9479c82de24ba1fb086b2",
            "dee886eae30941a987b686e7e83bffe4",
            "12c81fe388ec4df79dffaffb6db6c812",
            "504e33f9d2d44abea4a436b7cec6fe63",
            "2b9ffd2dacb54638aab659e8756af657",
            "accb1caf4acc4c1d92187c36e2a188a9",
            "5293ce7c70824542a80dbcaa12a9441a",
            "49563b5c3b5d4d8eb42140b20b7901e7",
            "aa8d7dfa0ea34a5697430f2bb5b02772",
            "dff78c1682794f55ade259e937ef4eff",
            "4ce74f01af4142f8b81c434425d5ea12",
            "b008b2973ccc44bdbe4af17758789e62",
            "e7a1ec75073f4aeebdf8b7db960de296",
            "16d6c05772704f1f8433867ae00cc703",
            "855188470d9342448f67d4dd5c9c4596",
            "c2e3b9b730b8468da72dbd7b1b0c99c7"
          ]
        },
        "id": "95S-tcq7Ih-u",
        "outputId": "4406c52d-3853-4333-c743-2cefa89c45ed"
      },
      "source": [
        "model = BertForMultipleChoice.from_pretrained('bert-base-uncased')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a411ecab81e9479c82de24ba1fb086b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa8d7dfa0ea34a5697430f2bb5b02772",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awQuZoQkJSd"
      },
      "source": [
        "### Send model to cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lox59M1Qxqp",
        "outputId": "c013c472-1389-41ac-f4fd-cb0f6fb612c4"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model.to(device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultipleChoice(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AL2uFrV2aRP"
      },
      "source": [
        "class Model(pl.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS)\n",
        "        self.model = model\n",
        "\n",
        "        self._train_dataloader = val_dataloader_drive\n",
        "        self._val_dataloader = val_dataloader_drive\n",
        "        self._test_dataloader = test_dataloader_drive\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        weight_decay = 0.0\n",
        "        adam_epsilon = 1e-8\n",
        "\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                'weight_decay': weight_decay\n",
        "                },\n",
        "            {\n",
        "                'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                'weight_decay': 0.0,\n",
        "                }\n",
        "            ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=adam_epsilon)\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        labels = batch[\"label\"]\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        token_type_ids = batch[\"token_type_ids\"]\n",
        "\n",
        "        outputs = self.model(\n",
        "                input_ids,\n",
        "                token_type_ids=token_type_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "                )\n",
        "\n",
        "        tqdm_dict = {\"train_loss\": outputs.loss}\n",
        "        output = OrderedDict({\n",
        "            \"loss\": outputs.loss,\n",
        "            \"progress_bar\": tqdm_dict,\n",
        "            \"log\": tqdm_dict,\n",
        "            })\n",
        "\n",
        "        return output\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        labels = batch[\"label\"]\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        token_type_ids = batch[\"token_type_ids\"]\n",
        "\n",
        "        outputs = self.model(\n",
        "                input_ids,\n",
        "                token_type_ids=token_type_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "                )\n",
        "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        correct_count = torch.sum(labels == labels_hat)\n",
        "\n",
        "        if self.on_gpu:\n",
        "            correct_count = correct_count.cuda(outputs.loss.device.index)\n",
        "\n",
        "        output = OrderedDict({\n",
        "                \"val_loss\": outputs.loss,\n",
        "                \"correct_count\": correct_count,\n",
        "                \"batch_size\": len(labels)\n",
        "                })\n",
        "        return output\n",
        "\n",
        "    def validation_end(self, outputs):\n",
        "        val_acc = sum([out[\"correct_count\"] for out in outputs]).float() / sum(out[\"batch_size\"] for out in outputs)\n",
        "        val_loss = sum([out[\"val_loss\"] for out in outputs]) / len(outputs)\n",
        "        tqdm_dict = {\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_acc\": val_acc,\n",
        "                }\n",
        "        return {\"progress_bar\": tqdm_dict, \"log\": tqdm_dict, \"val_loss\": val_loss}\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._train_dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._val_dataloader"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCSLab1C-mbY",
        "outputId": "2cb46763-ff00-4693-84c3-e840f5daee39"
      },
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "checkpoint_callback = ModelCheckpoint(dirpath='/content/drive/My Drive/Fachpraktikum/')\n",
        "trainer = pl.Trainer(gpus=1, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWYxUcL5tbSx",
        "outputId": "d0bfa47a-0607-41ab-f6c3-8a3ead109c83"
      },
      "source": [
        "model = Model()\n",
        "\n",
        "trainer.fit(model)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXGfhMCeE1dN",
        "outputId": "21cc6561-2068-4c2a-cc00-887fcb16ae0b"
      },
      "source": [
        "# test (pass in the loader)\n",
        "trainer.test(test_dataloaders=test_dataloader_drive)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you passed in a test_dataloader but have no test_step. Skipping test loop\n",
            "  warnings.warn(*args, **kwargs)\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}